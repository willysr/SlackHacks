--- NVIDIA-Linux-x86_64-390.138/kernel/common/inc/nv-linux.h.old   2020-12-20 10:49:24.536099286 +0700
+++ NVIDIA-Linux-x86_64-390.138/kernel/common/inc/nv-linux.h    2020-12-20 10:49:57.375309123 +0700
@@ -176,6 +176,9 @@
 #if defined(NV_VM_INSERT_PAGE_PRESENT)
 #include <linux/pagemap.h>
 #include <linux/dma-mapping.h>
+#else
+#include <linux/dma-direct.h>
+#include <linux/dma-map-ops.h>
 #endif
 
 #if defined(CONFIG_SWIOTLB) && defined(NVCPU_AARCH64)
 
diff --git a/kernel/conftest.sh b/kernel/conftest.sh
index ef82dee..1e64829 100755
--- a/kernel/conftest.sh
+++ b/kernel/conftest.sh
@@ -2050,6 +2050,7 @@ compile_test() {
             #include <linux/dma-mapping.h>
 #else
             #include <linux/dma-direct.h>
+            #include <linux/dma-map-ops.h>
 #endif
             void conftest_phys_to_dma(void) {
                 phys_to_dma();
@@ -2064,6 +2065,7 @@ compile_test() {
             #
             CODE="
             #include <linux/dma-mapping.h>
+            #include <linux/dma-map-ops.h>
             void conftest_dma_ops(void) {
                 (void)dma_ops;
             }"
@@ -2078,6 +2080,7 @@ compile_test() {
             #
             CODE="
             #include <linux/dma-mapping.h>
+            #include <linux/dma-map-ops.h>
             void conftest_dma_ops(void) {
                 (void)swiotlb_dma_ops;
             }"
@@ -2091,6 +2094,7 @@ compile_test() {
             # 
             CODE="
             #include <linux/dma-mapping.h>
+            #include <linux/dma-map-ops.h>
             void conftest_dma_map_ops(void) {
                 struct dma_map_ops ops;
             }"
@@ -2104,6 +2108,7 @@ compile_test() {
             #
             CODE="
             #include <linux/dma-mapping.h>
+            #include <linux/dma-map-ops.h>
             void conftest_get_dma_ops(void) {
                 get_dma_ops();
             }"
@@ -2117,6 +2122,7 @@ compile_test() {
             #
             CODE="
             #include <linux/dma-mapping.h>
+            #include <linux/dma-map-ops.h>
             void conftest_noncoherent_swiotlb_dma_ops(void) {
                 (void)noncoherent_swiotlb_dma_ops;
             }"
@@ -2133,6 +2139,7 @@ compile_test() {
             #
             CODE="
             #include <linux/dma-mapping.h>
+            #include <linux/dma-map-ops.h>
             void conftest_dma_map_resource(void) {
                 dma_map_resource();
             }"
@@ -3918,6 +3925,7 @@ compile_test() {
             #
             CODE="
             #include <linux/dma-mapping.h>
+            #include <linux/dma-map-ops.h>
             void conftest_dma_is_direct(void) {
                 dma_is_direct();
             }"
diff --git a/kernel/nvidia-drm/nvidia-drm-gem-user-memory.c b/kernel/nvidia-drm/nvidia-drm-gem-user-memory.c
index 76dedba..92a5192 100644
--- a/kernel/nvidia-drm/nvidia-drm-gem-user-memory.c
+++ b/kernel/nvidia-drm/nvidia-drm-gem-user-memory.c
@@ -20,6 +20,7 @@
  * DEALINGS IN THE SOFTWARE.
  */
 
+#include <linux/version.h>
 #include "nvidia-drm-conftest.h"
 
 #if defined(NV_DRM_AVAILABLE)
@@ -47,8 +48,13 @@ static struct sg_table *__nv_drm_gem_user_memory_prime_get_sg_table(
 {
     struct nv_drm_gem_user_memory *nv_user_memory = to_nv_user_memory(nv_gem);
 
-    return drm_prime_pages_to_sg(nv_user_memory->pages,
-                                 nv_user_memory->pages_count);
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(5, 10, 0))
+    return drm_prime_pages_to_sg(nv_gem->nv_dev->dev, nv_user_memory->pages,
+                                  nv_user_memory->pages_count);
+#else
+     return drm_prime_pages_to_sg(nv_user_memory->pages,
+                                  nv_user_memory->pages_count);
+#endif
 }
 
 static void *__nv_drm_gem_user_memory_prime_vmap(
